}
#apply function to the dataset
ended_match <- create_keyword_flags(ended_match, "cleaned_notes", all_keyword_lists)
#view first few rows of flag columns
ended_match %>%
select(contains("_flag")) %>%
head()
#define risk flag columns
risk_flag_cols <- names(ended_match)[grepl("_flag$", names(ended_match))]
ended_match %>%
group_by(closure_3_to_6) %>%
summarise(across(all_of(risk_flag_cols), mean))
plot_data <- ended_match %>%
select(closure_3_to_6, all_of(risk_flag_cols)) %>%
pivot_longer(cols = -closure_3_to_6, names_to = "risk_category", values_to = "flag")
#bar graphs for risk of closure categories
ggplot(plot_data, aes(x = risk_category, fill = as.factor(flag))) +
geom_bar(position = "fill") + coord_flip() +
facet_wrap(~ closure_3_to_6) +
labs(y = "Proportion", x = "Risk Category")
#load the original data
full_data <- read_csv("Training.csv")
#check the number of unique match ID
length(unique(full_data$`Match ID 18Char`)) #3275
#calculate the length between calls and match closure date
full_data$duration <- time_length(interval(full_data$`Completion Date`,
full_data$`Match Closure Meeting Date`),
"months")
#filter matches that ended and remove calls less than 3 months before closure
ended_match <- full_data[!is.na(full_data$duration), ] %>%
filter(!is.na(`Match Support Contact Notes`)) %>%
select(where(~ !all(is.na(.)))) %>%
filter(duration >= 3) %>%
mutate(closure_3_to_6 = if_else(duration >= 3 & duration <= 6, 1, 0))
#check again the number of unique match ID
length(unique(ended_match$`Match ID 18Char`)) #657
#check the number of calls for each match
num_calls <- ended_match %>%
count(`Match ID 18Char`, name = "Count")
#load common stop words
data("stop_words")
#define BBBS-specific stop words
bbbs_stopwords <- c(
"say", "ask", "talk", "question", "answer", "mec", "respond", "share", "comment",
"l_first_name", "b_first_name", "little", "big", "kit", "match", "bs", "mc", "ls",
"child", "activity", "didnt", "jj", "mia", "na", "ms", "activity",
"littles", "lfirstname", "llastname", "bigs", "bb", "lb", "bfirstname", "pg",
"tpm", "fb", "blastname", "shes", "im", "hasnt", "msc", "safety", "development",
"volunteer", "relationship", "bbbs", "concern", "note", "log", "meeting", "contact"
)
custom_stopwords <- bind_rows(stop_words,
tibble(word = bbbs_stopwords, lexicon = "bbbs"))
#create tokenized and lemmanized cleaned notes
ended_match <- ended_match %>%
mutate(cleaned_notes = `Match Support Contact Notes` %>%
tolower() %>%
str_replace_all("[^a-z\\s]", " ") %>%
str_squish()) %>%
rowwise() %>%
mutate(cleaned_notes = {
words <- unlist(str_split(cleaned_notes, "\\s+"))
lemmas <- lemmatize_words(words)
filtered <- lemmas[!lemmas %in% custom_stopwords$word]
str_c(filtered, collapse = " ")
}) %>%
ungroup()
#define keywords for risk of closure
closure_keywords <- list(
disengagement_risk = c(
"ghost", "unresponsive", "not", "no", "ignore", "non", "response", "respond",
"reachable", "difficult", "hard", "reach", "miss", "contact", "disconnect", "engage", "unavailable"
),
scheduling_issues = c(
"busy", "schedule", "reschedule", "cancel", "availability", "meeting", "conflict",
"time", "overlap", "inconsistent", "forgot", "late", "attendance", "miss"
),
emotional_distress = c(
"frustrate", "upset", "angry", "overwhelm", "stress", "emotional", "sad", "anxiety",
"disappoint", "burnout"
),
relationship_strain = c(
"awkward", "conflict", "strain", "argue", "disconnect", "tense", "forced", "lack",
"connection", "not", "bond", "negative", "unsuccessful", "issue"
),
family_issues = c(
"move", "divorce", "custody", "household", "transition", "family", "living", "parent",
"guardian", "sibling", "separate", "split", "instability", "step", "home", "crisis", "relocate"
),
match_concerns = c(
"closure", "terminate", "end", "concern", "issue", "problem", "not work",
"unsuccessful", "cancel", "discontinue", "stop", "talk", "discuss", "review"
),
life_changes = c("college", "university", "new school", "moving", "move", "moved", "relocate",
"relocation", "job", "career", "employment", "unemployed", "hired", "fired",
"layoff", "graduation", "graduate", "transfer", "transition", "change",
"divorce", "separated", "illness", "sick", "hospital", "surgery",
"baby", "newborn", "pregnant", "pregnancy")
)
#define keywords for compatibility
compatibility_keywords <- list(
interests = c(
"hiking", "fishing", "sports", "basketball", "soccer", "reading", "cooking", "game",
"drawing", "painting", "arts", "crafts", "running", "biking", "gymnastics", "skating",
"swimming", "yoga", "baking", "outdoors", "gardening", "camping", "lego", "photography",
"acting", "dancing", "singing", "puzzle", "animal", "pet", "cat", "dog"
),
personality = c(
"outgoing", "shy", "introvert", "extrovert", "energetic", "calm", "friendly", "bubbly",
"goofy", "creative", "funny", "sweet", "quiet", "thoughtful", "patient", "kind",
"reserved", "charismatic", "mature", "respectful", "empathetic", "responsible",
"imaginative", "lighthearted", "nurturing", "talkative"
),
proximity = c(
"close", "far", "mile", "minute", "drive", "commute", "convenient", "traffic",
"nearby", "distance", "location"
),
commitment = c(
"committed", "reliable", "consistent", "temporary", "longterm", "shortterm", "weekly",
"monthly", "available", "limited", "sporadic", "engagement", "involve", "attend"
),
experience = c(
"teacher", "mentor", "coach", "counsel", "nanny", "social", "childcare", "tutor",
"support", "educator", "facilitator", "leader", "background", "trainer", "youth"
),
preferences = c(
"younger", "older", "male", "female", "non-smoker", "religion", "christian", "catholic",
"hispanic", "african", "gender", "age", "cultural", "ethnic", "language", "no gun"
)
)
#combine all keyword categories into one list
all_keyword_lists <- c(closure_keywords, compatibility_keywords)
#define a function to create a binary indicator for each category
create_keyword_flags <- function(df, text_col, keyword_list) {
for (category in names(keyword_list)) {
pattern <- paste0("\\b(", paste(keyword_list[[category]], collapse = "|"), ")\\b")
df[[paste0(category, "_flag")]] <- ifelse(grepl(pattern, df[[text_col]], ignore.case = TRUE), 1, 0)
}
return(df)
}
#apply function to the dataset
ended_match <- create_keyword_flags(ended_match, "cleaned_notes", all_keyword_lists)
#view first few rows of flag columns
ended_match %>%
select(contains("_flag")) %>%
head()
#define risk flag columns
risk_flag_cols <- names(ended_match)[grepl("_flag$", names(ended_match))]
ended_match %>%
group_by(closure_3_to_6) %>%
summarise(across(all_of(risk_flag_cols), mean))
plot_data <- ended_match %>%
select(closure_3_to_6, all_of(risk_flag_cols)) %>%
pivot_longer(cols = -closure_3_to_6, names_to = "risk_category", values_to = "flag")
#bar graphs for risk of closure categories
ggplot(plot_data, aes(x = risk_category, fill = as.factor(flag))) +
geom_bar(position = "fill") + coord_flip() +
facet_wrap(~ closure_3_to_6) +
labs(y = "Proportion", x = "Risk Category")
#convert race descriptions of the Big and Little to be the same
race_mapping <- c(
"Black or African American" = "Black or African American",
"White or Caucasian" = "White",
"Hispanic" = "Hispanic or Latino",
"Asian" = "Asian",
"Pacific Islander - Native Hawaiian" = "Pacific Islander",
"Pacific Islander - Other" = "Pacific Islander",
"American Indian or Alaska Native" = "American Indian or Alaska Native",
"Prefer not to say" = "Prefer not to say",
"Other" = "Other",
"Asian - Other" = "Asian",
"Hispanic - Other Latinx or Spanish origin" = "Hispanic or Latino"
)
standardize_race <- function(race_string) {
if (is.na(race_string)) return(NA)
races <- str_split(race_string, ";")[[1]] %>%
str_trim() %>%  # Trim individual race entries
recode(!!!race_mapping) %>%
na.omit() %>%
unique() %>%
sort()
if (length(races) == 0) return(NA)
if (length(races) == 1) return(races[1])
clean_string <- paste(races, collapse = "; ")
clean_string <- str_trim(clean_string)
clean_string <- str_replace_all(clean_string, "^;\\s*|\\s*;$", "")
return(clean_string)
}
check_race_match <- function(big_race, little_race) {
if (is.na(big_race) || is.na(little_race)) return(0)
big_races <- str_split(big_race, ";\\s*")[[1]]
little_races <- str_split(little_race, ";\\s*")[[1]]
if (length(intersect(big_races, little_races)) > 0) {
return(1)
} else {
return(0)
}
}
ended_match <- ended_match %>%
mutate(
Big_Race_Standard = map_chr(`Big Race/Ethnicity`, standardize_race),
Little_Race_Standard = map_chr(`Little Participant: Race/Ethnicity`, standardize_race),
Big_Race_Standard = ifelse(Big_Race_Standard == "Prefer not to say", NA, Big_Race_Standard),
Little_Race_Standard = ifelse(Little_Race_Standard == "Prefer not to say", NA, Little_Race_Standard)
)
unique(ended_match$Big_Race_Standard)
unique(ended_match$Little_Race_Standard)
unique(ended_match$`Big Languages`)
unique(ended_match$`Little Contact: Language(s) Spoken`)
#calculate age differences and check if genders and ethnicity are the same
ended_match <- ended_match %>%
mutate(
Big_Age = as.numeric(difftime(Sys.Date(), `Big Birthdate`, units = "days")) / 365.25,
Little_Age = as.numeric(difftime(Sys.Date(), `Little Birthdate`, units = "days")) / 365.25,
age_difference = Big_Age - Little_Age,
same_gender = ifelse(`Big Gender` == `Little Gender`, 1, 0),
same_race_ethnicity = map2_int(Big_Race_Standard, Little_Race_Standard, check_race_match)
)
#check the distribution of age differences
ggplot(ended_match, aes(x = age_difference, fill = as.factor(closure_3_to_6))) +
geom_histogram()
ggplot(ended_match, aes(x = as.factor(closure_3_to_6), y = age_difference,
fill = as.factor(closure_3_to_6))) +
geom_boxplot()
#check the proportion of closure in 3 to 6 months across gender and ethnicity categories
ggplot(ended_match, aes(x = as.factor(same_gender), fill = as.factor(closure_3_to_6))) +
geom_bar(position = "fill")
ggplot(ended_match, aes(x = as.factor(same_race_ethnicity), fill = as.factor(closure_3_to_6))) +
geom_bar(position = "fill")
#define a logistic regression model with all risk of closure indicators
predictors <- c(risk_flag_cols, "age_difference", "same_gender", "same_race_ethnicity")
glm1 <- glm(closure_3_to_6 ~ .,
data = ended_match %>% select(closure_3_to_6, all_of(predictors)),
family = "binomial")
summary(glm1)
knitr::opts_chunk$set(collapse = TRUE,
prompt = FALSE,
message = FALSE, warning = FALSE, fig.align = "center")
library(tidyverse)
library(sp)
library(tigris)
library(ggmap)
library(tidycensus)
library(maditr)
library(spdep)
library(spatialreg)
library(gridExtra)
library(sf)
library(here)
library(dplyr)
library(rdist)
library(geosphere)
library(readxl)
#load the original data
full_data <- read_csv("../Data/Training.csv")
#load the original data
full_data <- read_csv("Training.csv")
average_match_length <- full_data %>%
filter(!is.na(`Little Mailing Address Census Block Group`)) %>%  # Remove rows without Census Block Group
group_by(`Little Mailing Address Census Block Group`) %>%
summarise(
avg_match_length_days = mean(match_length_days, na.rm = TRUE),
avg_match_length_months = mean(match_length_months, na.rm = TRUE),
n = n()  # Number of matches in the block group
) %>%
arrange(desc(avg_match_length_months))
average_match_length <- full_data %>%
filter(!is.na(`Little Mailing Address Census Block Group`)) %>%  # Remove rows without Census Block Group
group_by(`Little Mailing Address Census Block Group`) %>%
summarise(
avg_match_length = mean(match_length),
n = n()
)
match_length <- full_data %>%
filter(!is.na(`Little Mailing Address Census Block Group`)) %>%  # Remove rows without Census Block Group
group_by(`Little Mailing Address Census Block Group`) %>%
summarise(
avg_match_length = mean(`Match Length`),
n = n()
)
View(match_length)
# Load block groups for Minnesota (Hennepin and Ramsey counties)
mn_block_groups <- block_groups(state = "MN", county = c("Hennepin", "Ramsey"), year = 2021, cb = TRUE)
# load in census tracts
mn_tracts <- tracts(state = "MN", county = c("Hennepin", "Ramsey"), year = 2021,)
mn_bgs <- block_groups(state = "MN", county = c("Hennepin", "Ramsey"), year = 2021)
View(mn_block_groups)
# load in census tracts and block groups
mn_tracts <- tracts(state = "MN", county = c("Hennepin", "Ramsey"), year = 2021)
mn_bgs <- block_groups(state = "MN", county = c("Hennepin", "Ramsey"), year = 2021)
crime_tracts <- left_join(baton_tracts@data, crime_ct_data,
by = c("GEOID" = "CT_ID"))
mn_tracts <- as_Spatial(mn_tracts)
mn_bgs <- as_Spatial(mn_bgs)
match_length <- full_data %>%
filter(!is.na(`Little Mailing Address Census Block Group`)) %>%  # Remove rows without Census Block Group
group_by(`Little Mailing Address Census Block Group`) %>%
summarise(
BG_ID = `Little Mailing Address Census Block Group`,
avg_match_length = mean(`Match Length`),
n = n()
)
View(match_length)
match_length <- full_data %>%
filter(!is.na(`Little Mailing Address Census Block Group`)) %>%  # Remove rows without Census Block Group
group_by(`Little Mailing Address Census Block Group`) %>%
summarise(
avg_match_length = mean(`Match Length`),
n = n()
) %>%
mutate(BG_ID = `Little Mailing Address Census Block Group`)
View(match_length)
match_length_bgs <- left_join(mn_bgs@data, match_length,
by = c("GEOID" = "CT_ID"))
match_length_bgs <- left_join(mn_bgs@data, match_length,
by = c("GEOID" = "BG_ID"))
match_length <- full_data %>%
filter(!is.na(`Little Mailing Address Census Block Group`)) %>%  # Remove rows without Census Block Group
group_by(`Little Mailing Address Census Block Group`) %>%
summarise(
avg_match_length = mean(`Match Length`),
n = n()
) %>%
mutate(BG_ID = as.character(`Little Mailing Address Census Block Group`))
match_length_bgs <- left_join(mn_bgs@data, match_length,
by = c("GEOID" = "BG_ID"))
View(match_length_bgs)
mn_map <- ggmap(get_stadiamap(
c(left = -93.6, bottom = 44.7, right = -92.9, top = 45.2),
source = "stamen",
zoom = 11,
color = "bw"
))
ggmap(get_stadiamap(
c(left = -93.6, bottom = 44.7, right = -92.9, top = 45.2),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = mn_bgs@data, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void() +
labs(title = "Total BRPD IPV Crime Count in \nBaton Rouge by Census Tract",
fill = "Total \nIPV Crime Count") +
theme(text = element_text(family = "Times"),
plot.title = element_text(hjust = 0.5))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void() +
labs(title = "Total BRPD IPV Crime Count in \nBaton Rouge by Census Tract",
fill = "Total \nIPV Crime Count") +
theme(text = element_text(family = "Times"),
plot.title = element_text(hjust = 0.5))
mn_map <- ggmap(get_stadiamap(
c(left = -93.6, bottom = 44.7, right = -92.9, top = 45.2),
source = "stamen",
zoom = 11,
color = "bw"
))
match_length_bgs_sf <- st_as_sf(match_length_bgs)
mn_bgs_sf <- st_as_sf(mn_bgs)
match_length_bgs <- left_join(mn_bgs_sf, match_length,
by = c("GEOID" = "BG_ID"))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray")
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map <- ggmap(get_stadiamap(
c(left = -93.6, bottom = 44.5, right = -92.9, top = 45.4),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map <- ggmap(get_stadiamap(
c(left = -93.6, bottom = 44.2, right = -92.9, top = 45.3),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map <- ggmap(get_stadiamap(
c(left = -93.6, bottom = 44.8, right = -92.9, top = 45.3),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map <- ggmap(get_stadiamap(
c(left = -93.6, bottom = 44.7, right = -92.9, top = 45.3),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map <- ggmap(get_stadiamap(
c(left = -93.7, bottom = 44.75, right = -92.9, top = 45.3),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map <- ggmap(get_stadiamap(
c(left = -93.8, bottom = 44.75, right = -92.9, top = 45.3),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = match_length_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
match_length_big <- full_data %>%
filter(!is.na(`Big Home Census Block Group`)) %>%
group_by(`Big Home Census Block Group`) %>%
summarise(
avg_match_length = mean(`Match Length`),
n = n()
) %>%
mutate(BG_ID = as.character(`Big Home Census Block Group`))
big_bgs <- left_join(mn_bgs_sf, match_length_big,
by = c("GEOID" = "BG_ID"))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = little_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
little_bgs <- left_join(mn_bgs_sf, match_length_little,
by = c("GEOID" = "BG_ID"))
#create average match length data by census block group
match_length_little <- full_data %>%
filter(!is.na(`Little Mailing Address Census Block Group`)) %>%
group_by(`Little Mailing Address Census Block Group`) %>%
summarise(
avg_match_length = mean(`Match Length`),
n = n()
) %>%
mutate(BG_ID = as.character(`Little Mailing Address Census Block Group`))
match_length_big <- full_data %>%
filter(!is.na(`Big Home Census Block Group`)) %>%
group_by(`Big Home Census Block Group`) %>%
summarise(
avg_match_length = mean(`Match Length`),
n = n()
) %>%
mutate(BG_ID = as.character(`Big Home Census Block Group`))
# load in census tracts and block groups
mn_tracts <- tracts(state = "MN", county = c("Hennepin", "Ramsey"), year = 2021)
mn_tracts <- as_Spatial(mn_tracts)
mn_bgs <- block_groups(state = "MN", county = c("Hennepin", "Ramsey"), year = 2021)
mn_bgs <- as_Spatial(mn_bgs)
mn_bgs_sf <- st_as_sf(mn_bgs)
little_bgs <- left_join(mn_bgs_sf, match_length_little,
by = c("GEOID" = "BG_ID"))
big_bgs <- left_join(mn_bgs_sf, match_length_big,
by = c("GEOID" = "BG_ID"))
mn_map <- ggmap(get_stadiamap(
c(left = -93.8, bottom = 44.75, right = -92.9, top = 45.3),
source = "stamen",
zoom = 11,
color = "bw"
))
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = little_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = big_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = little_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
mn_map + geom_sf(aes(geometry = geometry, fill = avg_match_length),
data = big_bgs, col = "black",
linewidth = 0.5, inherit.aes = FALSE) +
scale_fill_distiller(palette = "Spectral", label = scales::comma,
na.value = "gray") + theme_void()
