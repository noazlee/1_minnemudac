---
title: "MinneMUDAC DS - Undergrad Questions 2"
subtitle: "Noah Lee"
output:
  pdf_document: default
  html_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r}
#| include: false
library(tidyverse)
library(tidymodels)
library(naniar)    
library(dplyr)
library(ggformula)
library(ggplot2) 
library(GGally)
library(survival)
library(lubridate)
library(ranger)   
library(workflows) 
library(recipes) 
```

# Predictive model for Match Length
Big Brother Big Sisters Twin Cities the largest and oldest youth award-winning mentoring organization in the greater Twin Cities.  Each year, we match up youth (Littles age 8-13) and their families with caring adults (Bigs) who volunteer as mentors.  Through a variety of community-based, school-based, and workplace-based mentoring programs, and together with our community, we want every youth to have a mentor, be affirmed in who they are, and explore who they want to be.

Preprocessing
```{r}
df <- read.csv('../Data/Training.csv')
extract_binary_indicators <- function(df) {
  # Initialize new columns with FALSE (0)
  interest_categories <- c("has_interests", "personality_compatibility", "has_proximity", 
                          "has_commitment", "has_experience", "has_preference",
                          "has_challenges", "has_goals")
  
  for (category in interest_categories) {
    df[[category]] <- FALSE  # Initialize with FALSE for all rows
  }
  
  # Define keywords for each category
  keywords <- list(
    has_interests = c("outdoors", "hiking", "biking", "fishing", "camping", "parks", "nature", "gardening", "swimming", "sledding", "horseback riding", "skateboarding", "snowboarding", "ice skating", "picnics", "planting", "rock climbing", "feeding ducks", "flying kites", "sports", "basketball", "football", "soccer", "baseball", "hockey", "bowling", "tennis", "running", "yoga", "Zumba", "gymnastics", "arts", "crafts", "drawing", "painting", "pottery", "sewing", "knitting", "photography", "model cars", "model planes", "creative activities", "acting", "singing", "dancing", "playing musical instruments", "writing","indoor activities", "reading", "cooking", "baking", "board games", "video games", "puzzles", "Lego", "animals", "dogs", "cats", "horses", "pets", "animal care", "learning", "science", "math", "history", "social studies", "STEM projects", "other interests", "fashion", "hair", "nails", "volunteering", "museums", "libraries", "zoos", "movies", "plays"),
    personality_compatibility = c("outgoing", "talkative", "bubbly", "energetic", "enthusiastic", "charismatic", 
                                "shy", "reserved", "quiet", "introverted", "soft-spoken", "calm", 
                                "adventurous", "curious", "exploratory", "open to new things", 
                                "friendly", "kind", "sweet", "thoughtful", "empathetic", 
                                "funny", "goofy", "humorous", "light-hearted", 
                                "mature", "respectful", "responsible", "thoughtful", 
                                "active", "sporty", "energetic", "athletic", 
                                "creative", "imaginative", "artistic", "crafty", 
                                "patient", "calm", "steady", "nurturing"),
    has_proximity = c("miles", "minutes", "close", "far", "convenient", "driving", "traffic", "commute"),
    has_commitment = c("long-term", "committed", "consistent", "reliable", "short-term", "temporary", "limited time", "2-4 times a month", "weekly"),
    has_experience = c("child experience", "nanny", "teacher", "coach", "mentor", "social work", "counseling", "teaching", "overcoming challenges", "mental health"),
    has_preference= c("age", "younger", "older", "in 20s", "gender", "male", "female", "religion", "Christian", "Catholic", "cultural background", "African American", "Hispanic", "non-smoker", "no guns"),
    has_challenges = c("behavioral challenges", "ADHD", "unmedicated", "redirection", "mental health", "depression", "anxiety", "PTSD", "family dynamics", "divorce", "strained relationships", "bullying", "picked on", "self-esteem", "academic challenges", "tutoring", "homework help"),
    has_goals = c("self-esteem", "confidence", "self-image", "leadership", "decision-making", "independence", "academic success", "math", "science", "reading", "social skills", "communication", "making friends", "exploration", "trying new things", "learning new skills")
  )
  
  # Check if Rationale.for.Match column exists in the dataframe
  if (!"Rationale.for.Match" %in% names(df)) {
    warning("Column 'Rationale.for.Match' not found in dataframe. No keywords will be extracted.")
    # Return dataframe with all FALSE values
    return(df)
  }
  
  # Process each row
  for (i in 1:nrow(df)) {
    rationale <- df$Rationale.for.Match[i]
    
    # Skip if rationale is NA or empty
    if (is.na(rationale) || rationale == "") {
      next
    }
    
    # Check for keywords in each category
    for (category in names(keywords)) {
      category_keywords <- keywords[[category]]
      for (keyword in category_keywords) {
        if (grepl(keyword, rationale, ignore.case = TRUE)) {
          df[[category]][i] <- TRUE
          break 
        }
      }
    }
  }
  
  # Convert logical columns to factors (0/1)
  for (category in interest_categories) {
    df[[category]] <- as.factor(as.integer(df[[category]]))
  }
  
  return(df)
}

df <- extract_binary_indicators(df)
df$Little.ID <- NULL
df$Big.ID <- NULL
df$Big.Employer <- NULL
df$Closure.Details <- NULL
df$Big.Open.to.Cross.Gender.Match <- NULL
df$Big.Contact..Interest.Finder...Sports <- NULL
df$Big.Contact..Interest.Finder...Places.To.Go <- NULL
df$Big.Contact..Interest.Finder...Hobbies <- NULL
df$Big.Contact..Interest.Finder...Entertainment <- NULL
df$Big.Contact..Interest.Finder...Hobbies <- NULL
df$Big.Contact..Created.Date <- NULL
df$Big.Enrollment..Created.Date <- NULL
df$Little.Contact..Interest.Finder...Sports <- NULL
df$Little.Contact..Interest.Finder...Outdoors <- NULL
df$Little.Contact..Interest.Finder...Arts <- NULL
df$Little.Contact..Interest.Finder...Places.To.Go <- NULL
df$Little.Contact..Interest.Finder...Hobbies <- NULL
df$Little.Contact..Interest.Finder...Entertainment <- NULL
df$Little.Contact..Interest.Finder...Other.Interests <- NULL
df$Little.Other.Interests <- NULL
df$Little.Contact..Interest.Finder...Career <- NULL
df$Little.Contact..Interest.Finder...Personality <- NULL
df$Little.Contact..Interest.Finder...Three.Wishes <- NULL
df$Little.Other.Interests <- NULL
df$Rationale.for.Match <- NULL
df$Big.County[df$Big.County == ""] <- NA
df$Match.Activation.Date <- as.Date(df$Match.Activation.Date, format="%Y-%m-%d")
df$Big.Approved.Date <- as.Date(df$Big.Approved.Date, format="%Y-%m-%d") 
df$Big.Acceptance.Date <- as.Date(df$Big.Acceptance.Date, format="%Y-%m-%d") 
df$Match.Closure.Meeting.Date <- as.Date(df$Match.Closure.Meeting.Date, format="%Y-%m-%d") 
df$Big.Birthdate <- as.Date(df$Big.Birthdate, format="%Y-%m-%d") 
df$Little.Birthdate <- as.Date(df$Little.Birthdate, format="%Y-%m-%d") 
df$Little.Interview.Date <- as.Date(df$Little.Interview.Date, format="%Y-%m-%d") 
df$Little.RTBM.Date.in.MF <- as.Date(df$Little.RTBM.Date.in.MF, format="%Y-%m-%d") 
#Function to check if Big and Little ethnicities share any keywords
check_ethnicity_match <- function(df) {
  # Create a new column to store the matching result
  df$Ethnicity_Match <- FALSE
  
  # Loop through each row
  for (i in 1:nrow(df)) {
    # Get the Big and Little race/ethnicity values
    big_race <- df$Big.Race.Ethnicity[i]
    little_race <- df$Little.Participant..Race.Ethnicity[i]
    
    # Skip if either value is NA
    if (is.na(big_race) || is.na(little_race)) {
      df$Ethnicity_Match[i] <- NA
      next
    }
    
    # Convert to character (in case they're factors)
    big_race <- as.character(big_race)
    little_race <- as.character(little_race)
    
    # Split strings by semicolons to handle multiple ethnicities
    big_races <- unlist(strsplit(big_race, ";"))
    little_races <- unlist(strsplit(little_race, ";"))
    
    # Clean up any leading/trailing spaces
    big_races <- trimws(big_races)
    little_races <- trimws(little_races)
    
    # Check if there's any match
    match_found <- FALSE
    for (b in big_races) {
      for (l in little_races) {
        # Extract keywords to compare (simplify the comparison)
        keywords <- c("White", "Black", "Asian", "Hispanic", "Indian", "Alaska", 
                     "Middle Eastern", "North African", "Other")
        
        # Check for each keyword
        for (keyword in keywords) {
          if (grepl(keyword, b, ignore.case = TRUE) && 
              grepl(keyword, l, ignore.case = TRUE)) {
            match_found <- TRUE
            break
          }
        }
        if (match_found) break
      }
      if (match_found) break
    }
    
    # Assign the result
    df$Ethnicity_Match[i] <- match_found
  }
  
  return(df)
}

df <- check_ethnicity_match(df)
df$Stage <- factor(ifelse(df$Stage == "Closed", "Closed", "Active"))
df[df == ""] <- NA
df$Big.Languages[df$Big.Languages == ""] <- NA
df$Big.Gender <- factor(df$Big.Gender, 
                        levels = c("Female", "Male"),
                        labels = c("Female", "Male"))
df$Big..Military <- NULL
df$Program <- as.factor(df$Program)
df$Program.Type <- as.factor(df$Program.Type)
df$Big.Languages <- NULL
df$Big.Contact..Preferred.Communication.Type <- NULL
df$Big.Contact..Former.Big.Little <- NULL
df$Big.Contact..Volunteer.Availability <- NULL
# df$Little.RTBM.Date.in.MF <- NULL
df$Little.Contact..Language.s..Spoken <- NULL
df$Little.Acceptance.Date <- NULL
df$Little.Application.Received <- NULL
df$Little.Moved.to.RTBM.in.MF <- NULL
df$Little.Mailing.Address.Census.Block.Group <- NULL
df$Little.Acceptance.Date <- NULL
df$Big.Home.Census.Block.Group <- NULL
df$Big.Employer.School.Census.Block.Group <- NULL
df$Little.Gender <- NULL
df$Little.Birthdate <- NULL
df$Little.RTBM.in.Matchforce <- NULL
df$Little.Interview.Date <- NULL
df$Big.Acceptance.Date <- NULL
df$Big.Assessment.Uploaded <- NULL
df$Big.Days.Interview.to.Match <- NULL
df$Big.Days.Interview.to.Acceptance <- NULL
consolidate_counties <- function(county_data, min_frequency = 50) {
  consolidated <- county_data
  county_counts <- table(county_data[county_data != ""])
  rare_counties <- names(county_counts[county_counts < min_frequency])
  consolidated[consolidated %in% rare_counties] <- "Other"
  # Convert to factor with meaningful levels
  consolidated <- factor(consolidated)
  
  return(consolidated)
}

df$County_Factor <- consolidate_counties(df$Big.County)
summary(df$County_Factor)
df$Big.County <- NULL
# Function to categorize text fields based on keywords
categorize_text <- function(text_vector, category_rules, default_category = "Other") {
  result <- rep(default_category, length(text_vector))
  
  if (any(is.na(text_vector))) {
    result[is.na(text_vector)] <- NA
  }
  
  text_vector <- tolower(trimws(text_vector))
  
  for (category_name in names(category_rules)) {
    keywords <- category_rules[[category_name]]
    
    # Check if any keyword appears in each entry
    match_indices <- sapply(text_vector, function(text) any(grepl(paste(keywords, collapse = "|"), text, ignore.case = TRUE)))
    
    # Assign the category where matches occur
    result[match_indices] <- category_name
  }
  
  return(factor(result))
}

# Define category rules for each text field
closure_reason_rules <- list(
  "Scheduling_Issues" = c("schedule", "time", "availability", "busy", "time constraint"),
  "Relationship_Problems" = c("relationship", "conflict", "disagree", "personal", "not compatible", "incompatible", "lost contact", "lost interest"),
  "Relocation" = c("move", "moved", "relocation", "relocate", "different city", "different state"),
  "Family_Issues" = c("family", "parent", "guardian", "parental"),
  "School_Issues" = c("school", "academic", "education", "grade", "graduated", "graduate"),
  "Health_Issues" = c("health", "illness", "medical", "sick", "disease", "covid", "deceased"),
  "Behavior_Issues" = c("behavior", "conduct", "attitude", "disciplin"),
  "Program_Requirements" = c("requirement", "qualify", "eligibility", "criteria", "guideline", "infraction", "expectations", "challenges"),
  "Success" = c("success", "successful")
)

occupation_rules <- list(
  "Business_Finance" = c("account", "financ", "budget", "analyst", "bank", "economic", "market", "business", "consultant", "insurance", "entrepreneur"),
  "Education" = c("teach", "professor", "instructor", "education", "academic", "school", "college", "university"),
  "Healthcare" = c("doctor", "nurse", "medical", "health", "dental", "therapist", "clinic", "hospital", "coach"),
  "Technology" = c("software", "developer", "engineer", "IT", "computer", "tech", "program", "web", "data"),
  "Legal" = c("lawyer", "attorney", "legal", "law", "judge", "paralegal"),
  "Arts_Media" = c("artist", "design", "writer", "media", "journalist", "creative", "music", "film", "arts"),
  "Service_Industry" = c("retail", "sales", "service", "hospitality", "restaurant", "customer", "child"),
  "Trades_Labor" = c("construct", "mechanic", "carpenter", "electric", "plumb", "repair", "builder", "labor"),
  "Student" = c("student", "graduate", "undergrad"),
  "Unknown" = c("unknown"),
  "Retired" = c("retire")
)

df$Closure_Reason_Category <- categorize_text(df$Closure.Reason, closure_reason_rules)
df$Occupation_Category <- categorize_text(df$Big.Occupation, occupation_rules)
summary(df$Closure_Reason_Category)
summary(df$Occupation_Category)
df$Closure.Reason <- NULL
df$Big.Occupation <- NULL
df$Big.Days.Acceptance.to.Match <- abs(df$Big.Days.Acceptance.to.Match)

# Sort the original DataFrame in place
df <- df[order(df$Match.Activation.Date), ]
# Create a factor variable with two levels
df$Big.Enrollment..Record.Type <- factor(
  ifelse(df$Big.Enrollment..Record.Type == "CB Volunteer Enrollment", 
         "CB Volunteer Enrollment", 
         "Others")
)
# Create new categorical variable from Big.Contact..Marital.Status
df$Big.Contact..Marital.Status <- factor(
  case_when(
    df$Big.Contact..Marital.Status == "Single" ~ "Single",
    !is.na(df$Big.Contact..Marital.Status) ~ "Not Single",
    TRUE ~ NA_character_
  ),
  levels = c("Single", "Not Single")
)
df$Stage <- ifelse(df$Stage == "Closed", 1, 0)
```

MONTHS UNTIL MATCH ENDED (FROM LOG):
```{r}
missing_closure_dates <- df %>%
  filter(Stage == 1 & is.na(Match.Closure.Meeting.Date)) %>%
  nrow()

df <- df %>%
  mutate(
    # Convert dates to ensure they're in Date format
    Match.Activation.Date = as.Date(Match.Activation.Date),
    Match.Closure.Meeting.Date = as.Date(Match.Closure.Meeting.Date),
    
    # Fill in missing closure dates for closed matches
    Match.Closure.Meeting.Date = case_when(
      # If it's a closed match with missing closure date but has activation date and match length
      Stage == 1 & is.na(Match.Closure.Meeting.Date) & !is.na(Match.Activation.Date) & !is.na(Match.Length) ~
        Match.Activation.Date + days(round(Match.Length * 30.44)), # Convert months to days
      
      # Otherwise keep the original value
      TRUE ~ Match.Closure.Meeting.Date
    )
  )

df <- df %>%
  mutate(
    Completion.Date = as.Date(Completion.Date),
    Match.Closure.Meeting.Date = as.Date(Match.Closure.Meeting.Date),
    
    # Calculate months_to_closure - time from log to closure date in months
    # For rows where Stage == 0 (closed matches), calculate the difference
    # For rows where Stage == 1 (active matches), set to NA
    months_to_closure = case_when(
      Stage == 1 & !is.na(Completion.Date) & !is.na(Match.Closure.Meeting.Date) ~ 
        round(as.numeric(interval(Completion.Date, Match.Closure.Meeting.Date) / months(1)), 1),
      Stage == 0 ~ NA_real_,  # Set to NA for active matches
      TRUE ~ NA_real_  # Handle any other cases (missing dates, etc.)
    )
  )

# Verify the new column was created correctly
summary(df$months_to_closure)

# Check some examples
head(df %>% select(Match.ID.18Char, Completion.Date, Match.Closure.Meeting.Date, Stage, months_to_closure))

# Save the updated dataframe
write.csv(df, "df_with_months_to_closure.csv", row.names = FALSE)
df
```


## Looking at df$'Match.Support.Contact.Notes'
```{r}
format_string <- function(input_string) {
  formatted_string <- gsub("(Question:|Answer:)", "\n\\1", input_string)
  formatted_string <- gsub("(Question:|Answer:)", "\\1\n", formatted_string)
  return(formatted_string)
}

cat(format_string(df$`Match.Support.Contact.Notes`[1:4]))
```

```{r}
library(tidyverse)
library(tidytext)
library(textstem)  # For proper lemmatization

# Define BBBS-specific stopwords
bbbs_stopwords <- c(
  "said", "asked", "question", "answer", "mec", "responded", "shared", "commented",
  "l_first_name", "b_first_name", "little", "big", "kit", "match", "bs", "mc", "ls",
  "child", "volunteer", "safety", "development", "activity", "activities",
  "relationship", "bbbs", "concern", "note", "log", "meeting", "contact"
)

# Create a function for properly cleaning and lemmatizing text
clean_and_lemmatize_notes <- function(notes) {
  # Handle NA or empty strings
  if (is.na(notes) || notes == "") {
    return("")
  }
  
  # Clean the text
  clean_text <- notes %>%
    # Convert to lowercase
    tolower() %>%
    # Remove "Question: Category: Answer:" patterns
    str_replace_all("question:\\s*[^:]+:\\s*answer:\\s*", " ") %>%
    # Remove "MEC asked, ... shared/responded" patterns
    str_replace_all("mec asked,\\s*[^?]+\\?\\s*\\w+ (shared|responded|commented)[^.]*", " ") %>%
    # Replace common name patterns
    str_replace_all("l_first_name|b_first_name", " ") %>%
    # Remove punctuation and replace with spaces
    str_replace_all("[[:punct:]]", " ") %>%
    # Replace multiple spaces with a single space
    str_replace_all("\\s+", " ") %>%
    # Trim leading/trailing whitespace
    str_trim()
  
  # Tokenize the text
  tokens_df <- tibble(text = clean_text) %>%
    unnest_tokens(word, text) %>%
    # Remove stopwords (both standard and BBBS-specific)
    anti_join(tibble(word = c(stop_words$word, bbbs_stopwords)), by = "word") %>%
    # Remove short words
    filter(nchar(word) > 2)
  
  # Apply proper lemmatization
  lemmatized_words <- tokens_df %>%
    mutate(lemma = lemmatize_words(word))
  
  # Combine the tokens back into a string
  cleaned_text <- lemmatized_words %>%
    pull(lemma) %>%
    paste(collapse = " ")
  
  return(cleaned_text)
}

# Apply the function to create a new column
df$cleaned_notes <- sapply(df$`Match.Support.Contact.Notes`, clean_and_lemmatize_notes)

df
write.csv(df, "df.csv")
```

Features from cleaned text:
```{r}
dtm <- df %>%
  filter(cleaned_notes != "") %>%
  mutate(doc_id = row_number()) %>%
  unnest_tokens(word, cleaned_notes) %>%
  count(doc_id, word) %>%
  cast_dtm(doc_id, word, n)

improved_tfidf <- df %>%
  filter(cleaned_notes != "") %>%
  mutate(doc_id = row_number()) %>%
  unnest_tokens(word, cleaned_notes) %>%
  filter(!(word %in% c(stop_words$word, bbbs_stopwords))) %>%
  filter(!str_detect(word, "\\d")) %>%
  filter(str_detect(word, "^[a-z]+$")) %>%
  filter(nchar(word) > 3) %>%
  filter(!(word %in% c("ltk", "sbf", "jpg", "dae", "conuct", "attened", "herslef"))) %>%
  count(doc_id, word) %>%
  bind_tf_idf(word, doc_id, n)

word_counts <- improved_tfidf %>%
  group_by(word) %>%
  summarize(doc_count = n_distinct(doc_id))

meaningful_tfidf <- improved_tfidf %>%
  inner_join(word_counts %>% filter(doc_count >= 5), by = "word") %>%
  group_by(word) %>%
  summarize(mean_tf_idf = mean(tf_idf)) %>%
  arrange(desc(mean_tf_idf)) %>%
  head(20)

print(meaningful_tfidf)
```

Word frequency:
```{r}
top_words <- df %>%
  filter(cleaned_notes != "") %>%
  unnest_tokens(word, cleaned_notes) %>%
  count(word, sort = TRUE) %>%
  head(100) %>%
  pull(word)

top_words
```

Topic model:
```{r}
library(topicmodels)

# LDA model with 10 topics
lda_model <- LDA(dtm, k = 10, control = list(seed = 1234))

# Extract topic-word probabilities
topics <- tidy(lda_model, matrix = "beta")

# Get top terms for each topic
top_terms <- topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  arrange(topic, -beta)

# Convert doc_id to character in doc_topics
doc_topics <- tidy(lda_model, matrix = "gamma") %>%
  rename(doc_id = document) %>%
  mutate(doc_id = as.character(doc_id))

# Print to check structure
print(head(doc_topics))

# Create doc_id_map with character IDs
doc_id_map <- df %>%
  filter(cleaned_notes != "") %>%
  mutate(doc_id = as.character(row_number())) %>%
  select(Match.ID.18Char, doc_id)

# Join and pivot without grouping
topic_df <- doc_topics %>%
  left_join(doc_id_map, by = "doc_id") %>%
  # Filter out NAs
  filter(!is.na(Match.ID.18Char)) %>%
  # Group by match ID and topic, then calculate mean gamma
  group_by(Match.ID.18Char, topic) %>%
  summarize(gamma = mean(gamma, na.rm = TRUE), .groups = "drop") %>%
  # Now pivot
  pivot_wider(
    id_cols = Match.ID.18Char,
    names_from = topic,
    values_from = gamma,
    names_prefix = "topic_"
  )

topic_df
# df <- df %>%
#   left_join(topic_df, by = "Match.ID.18Char") - analyse importance of topic compared to match length
```

```{r}
# 1. First, join the topic probabilities with match length data
match_topic_data <- df %>%
  select(Match.ID.18Char, Match.Length) %>%
  right_join(topic_df, by = "Match.ID.18Char") %>%
  filter(!is.na(Match.Length))

# 2. Get summary statistics for each topic
topic_summary <- match_topic_data %>%
  select(starts_with("topic_")) %>%
  summary()

print(topic_summary)

# 3. Calculate correlations between topics and match length
topic_correlations <- match_topic_data %>%
  select(Match.Length, starts_with("topic_")) %>%
  cor() %>%
  as.data.frame() %>%
  select(Match.Length) %>%
  filter(row.names(.) != "Match.Length") %>%
  arrange(desc(abs(Match.Length)))

print(topic_correlations)

# 4. Visualize top correlations
top_topics <- rownames(topic_correlations)[1:5]

match_topic_data %>%
  select(Match.Length, all_of(top_topics)) %>%
  pivot_longer(cols = all_of(top_topics), names_to = "topic", values_to = "probability") %>%
  ggplot(aes(x = probability, y = Match.Length)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  facet_wrap(~topic) +
  labs(title = "Relationship Between Top Topics and Match Length",
       x = "Topic Probability",
       y = "Match Length (months)")

# 5. Run a linear regression to assess significance
topic_model <- lm(Match.Length ~ ., data = match_topic_data %>% select(Match.Length, starts_with("topic_")))
topic_importance <- summary(topic_model)$coefficients %>%
  as.data.frame() %>%
  rownames_to_column("term") %>%
  filter(term != "(Intercept)") %>%
  arrange(desc(abs(`t value`)))

print(topic_importance)
```

```{r}
topic_3_words <- topics %>%
  filter(topic == 3) %>%
  arrange(desc(beta)) %>%
  head(20)  # Get top 20 words

print(topic_3_words)
```

```{r}
topic_3_docs <- doc_topics %>%
  filter(topic == 3) %>%
  arrange(desc(gamma)) %>%
  head(10) %>%  # Get top 10 documents
  select(doc_id, gamma)

topic_3_examples <- df %>%
  filter(cleaned_notes != "") %>%
  mutate(doc_id = as.character(row_number())) %>%
  inner_join(topic_3_docs, by = "doc_id") %>%
  select(Match.ID.18Char, doc_id, Match.Support.Contact.Notes, cleaned_notes, gamma) %>%
  arrange(desc(gamma))

# Print the top examples
print(topic_3_examples %>% select(Match.ID.18Char, doc_id, gamma))

# To see the full text of a specific example (e.g., the first one)
print(topic_3_examples$Match.Support.Contact.Notes[1])
print(topic_3_examples$cleaned_notes[1])
df
```

Sentiment analysis:
```{r}
library(tidyverse)
library(tidytext)

efficient_sentiment_analysis <- function(df) {
  bing_lexicon <- get_sentiments("bing")
  afinn_lexicon <- get_sentiments("afinn")
  
  joy_words <- c("happy", "enjoy", "joy", "fun", "love", "smile", "laugh", "excite", 
                "great", "well", "good", "nice", "awesome", "wonderful", "fantastic")
  
  trust_words <- c("trust", "honest", "loyal", "respect", "reliable", "depend", 
                  "faith", "believe", "confident", "committed", "responsible")
  
  fear_words <- c("fear", "afraid", "worry", "scared", "anxious", "nervous", 
                 "concern", "stress", "danger", "risk", "threat")
  
  anger_words <- c("anger", "angry", "mad", "hate", "rage", "irritate", "annoyed", 
                  "frustrate", "upset", "bitter", "hostile", "aggressive")
  
  sadness_words <- c("sad", "unhappy", "depress", "sorry", "grief", "disappoint", 
                    "miss", "hurt", "pain", "cry", "tear", "alone", "lonely")
  

  analyze_single_text <- function(text) {
    if (is.na(text) || text == "") {
      return(list(
        positive = 0, negative = 0, 
        bing_sentiment_score = 0, bing_sentiment_ratio = 0.5,
        afinn_sentiment_score = 0, afinn_word_count = 0, afinn_avg_score = 0,
        joy = 0, trust = 0, fear = 0, anger = 0, sadness = 0
      ))
    }
    
    words <- unlist(strsplit(text, "\\s+"))
    
    bing_matches <- bing_lexicon[bing_lexicon$word %in% words, ]
    positive_count <- sum(bing_matches$sentiment == "positive")
    negative_count <- sum(bing_matches$sentiment == "negative")
    bing_score <- positive_count - negative_count
    bing_ratio <- if ((positive_count + negative_count) > 0) {
      positive_count / (positive_count + negative_count)
    } else {
      0.5
    }
    
    afinn_matches <- afinn_lexicon[afinn_lexicon$word %in% words, ]
    afinn_score <- sum(afinn_matches$value)
    afinn_count <- nrow(afinn_matches)
    afinn_avg <- if (afinn_count > 0) afinn_score / afinn_count else 0
    
    joy_count <- sum(sapply(joy_words, function(w) sum(grepl(w, words))))
    trust_count <- sum(sapply(trust_words, function(w) sum(grepl(w, words))))
    fear_count <- sum(sapply(fear_words, function(w) sum(grepl(w, words))))
    anger_count <- sum(sapply(anger_words, function(w) sum(grepl(w, words))))
    sadness_count <- sum(sapply(sadness_words, function(w) sum(grepl(w, words))))
    
    return(list(
      positive = positive_count,
      negative = negative_count,
      bing_sentiment_score = bing_score,
      bing_sentiment_ratio = bing_ratio,
      afinn_sentiment_score = afinn_score,
      afinn_word_count = afinn_count,
      afinn_avg_score = afinn_avg,
      joy = joy_count,
      trust = trust_count,
      fear = fear_count,
      anger = anger_count,
      sadness = sadness_count
    ))
  }
  
  message("Starting sentiment analysis...")
  result <- df %>%
    rowwise() %>%
    mutate(
      sentiment_data = list(analyze_single_text(cleaned_notes)),
      positive = sentiment_data$positive,
      negative = sentiment_data$negative,
      bing_sentiment_score = sentiment_data$bing_sentiment_score,
      bing_sentiment_ratio = sentiment_data$bing_sentiment_ratio,
      afinn_sentiment_score = sentiment_data$afinn_sentiment_score,
      afinn_word_count = sentiment_data$afinn_word_count,
      afinn_avg_score = sentiment_data$afinn_avg_score,
      joy = sentiment_data$joy,
      trust = sentiment_data$trust,
      fear = sentiment_data$fear,
      anger = sentiment_data$anger,
      sadness = sentiment_data$sadness
    ) %>%
    select(-sentiment_data) %>%
    ungroup()
  
  message("Sentiment analysis completed.")
  return(result)
}

df_with_sentiment <- efficient_sentiment_analysis(df)

print(dim(df))
print(dim(df_with_sentiment))
```

```{r}
# Aggregate sentiment scores by Match ID for analysis
match_sentiment <- df_with_sentiment %>%
  group_by(Match.ID.18Char) %>%
  summarize(
    positive_sum = sum(positive),
    negative_sum = sum(negative),
    bing_score_avg = mean(bing_sentiment_score, na.rm = TRUE),
    bing_ratio_avg = mean(bing_sentiment_ratio, na.rm = TRUE),
    afinn_score_avg = mean(afinn_sentiment_score, na.rm = TRUE),
    joy_sum = sum(joy),
    trust_sum = sum(trust),
    fear_sum = sum(fear),
    anger_sum = sum(anger),
    sadness_sum = sum(sadness),
    log_count = n()
  )

# Join with match data
match_data <- df %>%
  select(Match.ID.18Char, Match.Length, months_to_closure) %>%
  distinct() %>%
  left_join(match_sentiment, by = "Match.ID.18Char")

# Create closing_soon variable
match_data <- match_data %>%
  mutate(closing_soon = ifelse(months_to_closure <= 3 & months_to_closure > 0, 1, 0))

# Analyze correlation with Match.Length in Matches closing soon
sentiment_correlation <- match_data %>%
  select(Match.Length, starts_with("positive"), starts_with("negative"), 
         starts_with("bing"), starts_with("afinn"), 
         joy_sum, trust_sum, fear_sum, anger_sum, sadness_sum) %>%
  cor(use = "pairwise.complete.obs") %>%
  as.data.frame() %>%
  select(Match.Length) %>%
  arrange(desc(abs(Match.Length)))

print("Correlation of sentiment features with Match.Length:")
print(sentiment_correlation)

df <- df %>%
  mutate(closing_soon = case_when(
    # Match will end within 3 months
    months_to_closure <= 3 & months_to_closure > 0 ~ 1,
    # Match will continue longer than 3 months
    months_to_closure > 3 ~ 0,
    # No closure date information or already closed
    TRUE ~ 0
  ))
```


```{r}
df2 <- df
df <- df %>%
  filter(closing_soon == 0)
```

```{r}
library(survival)
km_fit <- survfit(Surv(Match.Length, Stage) ~ 1, data = df)
print(summary(km_fit))

# Use median survival time from Kaplan-Meier as threshold (if available)
if(!is.null(km_fit$median)) {
  median_survival <- km_fit$median
} else {
  # Fallback if median survival time is not reached
  median_survival <- median(df$Match.Length, na.rm = TRUE)
}

# Categorize into long and short match logs
df$length_category <- ifelse(
  df$Match.Length > median_survival | 
    (df$match_ended == 0 & df$Match.Length > (median_survival/2) & df$Stage == 0),
  "long", 
  "short"
)

# Find most common words in the long ones


# Add as feature



# Consolidate df

# POTENTIAL THINGS TO LOOK AT 
# Time-dependent covariates:
# Track how sentiment, topic probabilities, and communication patterns change over time
# Word embedding features
# 
```


```{r}
# Appending sentiment analysis
sentiment_data <- df_with_sentiment %>%
  select(Match.ID.18Char, Completion.Date, positive, negative)

df <- df %>%
  left_join(sentiment_data, by = c("Match.ID.18Char", "Completion.Date")) %>%
  mutate(
    positive = ifelse(is.na(positive), 0, positive),
    negative = ifelse(is.na(negative), 0, negative)
  )
df2 <- df2 %>%
  left_join(sentiment_data, by = c("Match.ID.18Char", "Completion.Date")) %>%
  mutate(
    positive = ifelse(is.na(positive), 0, positive),
    negative = ifelse(is.na(negative), 0, negative)
  )

df
```

```{r}
write.csv(df, "df.csv")
```













